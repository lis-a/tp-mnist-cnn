# MNIST ‚Äì Deep Learning & MLOps

**Auteurs** : AU Lisa, HENRY Dorine

**Classe** : M2 TL - DC Paris

## Pr√©sentation du projet

Ce projet a √©t√© r√©alis√© dans le cadre du cours de Deep Learning et a pour objectifs :

- D‚Äôentra√Æner un mod√®le de classification d‚Äôimages manuscrites (dataset MNIST) avec PyTorch, en comparant notamment un MLP et un CNN.
- De mettre le mod√®le en production via une API FastAPI et une interface utilisateur Streamlit.
- De dockeriser l‚Äôensemble du projet avec Docker et Docker Compose.
- D‚Äôautomatiser le d√©ploiement de l‚Äôimage Docker de l‚ÄôAPI gr√¢ce √† **GitHub Actions**, en respectant les crit√®res du **niveau 1 MLOps** selon Google.

---

## 1. Entra√Ænement et comparaison des mod√®les

Deux mod√®les ont √©t√© entra√Æn√©s sur le dataset MNIST :

- Un perceptron multicouche (**MLP**)
- Un r√©seau de neurones convolutionnel (**CNN**)

### üîß Objectif
Comparer les performances des deux approches sur un m√™me volume de param√®tres pour mettre en √©vidence l‚Äôint√©r√™t du CNN pour le traitement d‚Äôimages.

### üìä R√©sultats

| Crit√®re             | CNN         | MLP         |
|---------------------|-------------|-------------|
| Nombre de param√®tres | ~6.42K      | ~6.44K      |
| Test loss           | 0.0994      | 0.4430      |
| Test accuracy       | 96.93%      | 87.22%      |

### üîé Analyse
Le CNN obtient de bien meilleures performances car :
- Il exploite la structure spatiale des images (convolutions, pooling‚Ä¶)
- Il d√©tecte mieux les motifs locaux (traits, contours‚Ä¶)

En comparaison, le MLP consid√®re chaque pixel ind√©pendamment, sans capturer les relations spatiales entre eux.

### ‚úÖ Conclusion
Le CNN g√©n√©ralise mieux sur des images comme celles du MNIST. Il converge plus rapidement, avec une meilleure pr√©cision, malgr√© un nombre de param√®tres comparable.

---

## 2. Effet de la permutation des pixels

Une exp√©rience a √©t√© men√©e pour √©tudier la robustesse des mod√®les face √† une perte de structure spatiale. Pour cela, on a appliqu√© une **permutation fixe** sur tous les pixels des images MNIST. Cela revient √† d√©sorganiser l‚Äôimage tout en conservant exactement les m√™mes valeurs de pixels.

### üéØ Objectif
Comparer les performances des mod√®les (CNN vs MLP) **avec des images permut√©es**.

### üìä R√©sultats

| Crit√®re               | CNN (permut√©) | MLP (permut√©) |
|-----------------------|---------------|---------------|
| Nombre de param√®tres | 6.422K        | 6.442K        |
| Test loss            | 0.3948        | 0.4516        |
| Test accuracy        | 88.05%        | 86.92%        |

### üß† Analyse

- **Le CNN**, qui d√©pend fortement de la structure spatiale des images, **voit ses performances fortement baisser** (~9 points de moins qu‚Äôen non permut√©).
- **Le MLP**, lui, traite d√©j√† les pixels comme un vecteur plat, donc la permutation ne l‚Äôaffecte presque pas.

### üìå Conclusion

Lorsque l‚Äôinformation spatiale est perturb√©e (permutation des pixels), **le CNN perd son avantage** sur le MLP. Cela montre l‚Äôimportance du format d‚Äôentr√©e pour les architectures √† base de convolutions.

---

## 3. Sauvegarde du mod√®le entra√Æn√©

Le mod√®le CNN entra√Æn√© sur les donn√©es MNIST non permut√©es a √©t√© sauvegard√© pour un usage futur, notamment lors de son d√©ploiement via une API ou une interface.

### üì¶ Format utilis√©
Le mod√®le a √©t√© sauvegard√© au format **PyTorch (.pt)**, contenant les poids du r√©seau.

### üíæ Code utilis√©

```python
# Sauvegarde du mod√®le CNN entra√Æn√©
torch.save(model.state_dict(), "model/mnist-0.0.1.pt")
`````

____

## 4. D√©ploiement local avec FastAPI

Afin de rendre le mod√®le accessible √† travers une API, nous avons utilis√© **FastAPI**, un framework l√©ger et rapide pour la cr√©ation de services web en Python.

### üöÄ Objectif
Permettre √† une application externe (frontend ou script) de faire des pr√©dictions en interrogeant une API HTTP.

### üîß Architecture

- Le code de l‚ÄôAPI est situ√© dans `src/app/main.py`
- Le mod√®le est charg√© depuis `model/mnist-0.0.1.pt`
- L‚ÄôAPI expose une route `POST /api/v1/predict` pour envoyer une image et obtenir une pr√©diction.

### üß™ Test de l‚ÄôAPI localement

Pour d√©marrer l‚ÄôAPI localement :

````bash
uvicorn src.app.main:app --reload bash
`````

Une fois lanc√©e, l‚Äôinterface Swagger est accessible √† :
üëâ http://localhost:8000/docs

### üì§ Format de requ√™te attendu
L‚ÄôAPI attend une image PNG encod√©e au format multipart/form-data.

### üì• Format de r√©ponse
L‚ÄôAPI retourne la pr√©diction au format JSON :


````json
{
  "prediction": 4
}
`````

### üîß D√©pendance n√©cessaire
Pour g√©rer les formulaires (envoi de fichiers), l‚Äôinstallation de la librairie suivante est requise :

````bash
pip install python-multipart
`````

----

## 5. Interface web avec Streamlit

Une interface utilisateur a √©t√© d√©velopp√©e avec **Streamlit** pour permettre de tester le mod√®le de mani√®re interactive.

### üéØ Objectif

Permettre √† l'utilisateur de dessiner un chiffre √† la souris et d'obtenir une pr√©diction instantan√©e √† partir du mod√®le entra√Æn√©.

### üß± Structure

- üìÑ `src/app/front.py` : code de l‚Äôinterface Streamlit
- L‚Äôinterface appelle l‚ÄôAPI FastAPI pour effectuer la pr√©diction

### üñåÔ∏è Fonctionnalit√© principale

Gr√¢ce au composant `streamlit-drawable-canvas`, l‚Äôutilisateur peut dessiner un chiffre √† la main (dans un canevas 28x28 pixels) puis l‚Äôenvoyer √† l‚ÄôAPI.

### ‚ñ∂Ô∏è Lancer l'interface localement

````bash
streamlit run src/app/front.py
`````

Ensuite, rendez-vous sur :
üëâ http://localhost:8501

### üîß D√©pendances n√©cessaires
Pour ex√©cuter cette interface, il est n√©cessaire d‚Äôinstaller les biblioth√®ques suivantes :

````bash
pip install streamlit streamlit-drawable-canvas
`````

----

## 6. Dockerisation et orchestration avec Docker Compose

### üéØ Objectif

Faciliter le d√©ploiement du projet en encapsulant l‚ÄôAPI FastAPI et l‚Äôinterface Streamlit dans des conteneurs Docker, orchestr√©s via `docker-compose`.


#### üèóÔ∏è Construire et lancer l‚Äôenvironnement

````bash
docker compose up --build
`````

L‚ÄôAPI est accessible √† l‚Äôadresse : http://localhost:8000/docs
L‚Äôinterface Streamlit est disponible sur : http://localhost:8501

---

## 7. üèóÔ∏è Industrialisation du projet
Afin de pr√©parer le projet √† une mise en production robuste et maintenable, nous avons structur√© le d√©p√¥t en suivant une architecture claire, inspir√©e des bonnes pratiques MLOps :

````bash
TP1/
‚îú‚îÄ‚îÄ model/                      # Mod√®le entra√Æn√© au format .pt
‚îú‚îÄ‚îÄ data/                      # Donn√©es MNIST t√©l√©charg√©es
‚îÇ   ‚îî‚îÄ‚îÄ raw/                   # Donn√©es brutes
‚îú‚îÄ‚îÄ notebook/                  # Fichiers exploratoires Jupyter
‚îÇ   ‚îî‚îÄ‚îÄ init.ipynb
‚îú‚îÄ‚îÄ src/                       # Code source Python
‚îÇ   ‚îú‚îÄ‚îÄ model/                 # Script d'entra√Ænement du mod√®le
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py
‚îÇ   ‚îî‚îÄ‚îÄ app/                   # Application API + Frontend
‚îÇ       ‚îú‚îÄ‚îÄ main.py            # Code de l'API FastAPI
‚îÇ       ‚îú‚îÄ‚îÄ front.py           # Interface utilisateur Streamlit
‚îÇ       ‚îú‚îÄ‚îÄ Dockerfile.api     # Dockerfile pour l'API
‚îÇ       ‚îî‚îÄ‚îÄ Dockerfile.front   # Dockerfile pour le front
‚îú‚îÄ‚îÄ docker-compose.yml         # Orchestration des services API/Front
‚îú‚îÄ‚îÄ .gitignore                 # Fichiers √† exclure du suivi Git
‚îî‚îÄ‚îÄ README.md                  # Pr√©sentation du projet

`````

### ‚öôÔ∏è Principes appliqu√©s

- **S√©paration des r√¥les** :
  - Le code de data science exploratoire (`notebook/`) est isol√© du code de production (`src/`).
  - Le mod√®le est sauvegard√© dans un dossier √† part (`model/`) pour faciliter les d√©ploiements.

- **Modularit√©** :
  - L‚ÄôAPI (`main.py`) est ind√©pendante du front (`front.py`) et chacun a son propre Dockerfile.

- **Pr√™t pour le d√©ploiement** :
  - Gr√¢ce √† `docker-compose.yml`, le projet est d√©ployable localement ou en production en une seule commande.
  - Les d√©pendances sont isol√©es dans des conteneurs.

- **MLOps niveau 1** :
  - Le d√©ploiement du mod√®le est automatis√© via un **workflow GitHub Actions** qui construit et pousse l'image Docker sur Docker Hub apr√®s chaque commit.


---

## 8. D√©ploiement automatique avec GitHub Actions (MLOps Niveau 1)

### üéØ Objectif

D√©ployer automatiquement l'image Docker de l‚ÄôAPI √† chaque mise √† jour du code sur GitHub.  
Cela r√©pond au **niveau 1** des pratiques MLOps selon Google :  
> Automatiser le d√©ploiement des mod√®les en production.

### üõ†Ô∏è √âtapes r√©alis√©es

1. Cr√©ation d‚Äôun d√©p√¥t distant sur [Docker Hub](https://hub.docker.com/)
2. Ajout d‚Äôun fichier GitHub Actions (`.github/workflows/docker-image.yml`) √† la racine du projet
3. Stockage des **secrets Docker Hub** (`DOCKER_USERNAME`, `DOCKER_PASSWORD`) dans les **Secrets GitHub**
4. √Ä chaque `git push`, le workflow :
   - construit l‚Äôimage Docker √† partir du `Dockerfile.api`
   - la pousse sur Docker Hub

Une fois configur√©, chaque commit d√©clenche automatiquement le pipeline de d√©ploiement.

--- 
## 9. Bilan et pistes d‚Äôam√©lioration

### ‚úÖ R√©sultats obtenus

- **Mod√®le entra√Æn√© avec succ√®s** sur le dataset MNIST
- **Comparaison CNN vs MLP** : meilleure pr√©cision pour le CNN (~97%)
- **D√©ploiement local fonctionnel** via **FastAPI** et interface avec **Streamlit**
- **Automatisation** du d√©ploiement Docker avec **GitHub Actions**

### üìà Am√©liorations possibles

- **Augmentation de donn√©es (Data Augmentation)** :
  - Rotation, zoom, translation pour rendre le mod√®le plus robuste
- **Mod√®le plus complexe** :
  - Ajouter des couches, augmenter le nombre de kernels
- **√âvaluation plus fine** :
  - Matrice de confusion, pr√©cision par chiffre
- **Meilleure UX dans le frontend** :
  - Pr√©visualisation claire du dessin
  - Indication de confiance de la pr√©diction
- **Ajout de tests automatis√©s** :
  - Pour v√©rifier les performances du mod√®le ou le bon fonctionnement de l'API
- **Suivi de version du mod√®le** :
  - Avec des outils comme DVC ou MLflow (niveau MLOps 2+)

---

üéì Ce TP constitue une premi√®re mise en ≈ìuvre des principes MLOps, en partant de l'entra√Ænement jusqu‚Äôau d√©ploiement continu d‚Äôun mod√®le simple.  
Il pourra √™tre r√©utilis√© comme base pour des cas plus complexes.
